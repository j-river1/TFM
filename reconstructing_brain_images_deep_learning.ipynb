{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reconstructing-brain-images-deep-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-river1/TFM/blob/master/reconstructing_brain_images_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMd0krGYdzee"
      },
      "source": [
        "**Reconstructing Brain MRI Images Using Deep Learning (Convolutional Autoencoder)**\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/reconstructing-brain-images-deep-learning\n",
        "\n",
        "In this tutorial, you'll learn & understand how to read nifti format brain magnetic resonance imaging (MRI) images, reconstructing them using convolutional autoencoder.\n",
        "You will use 3T brain MRI dataset to train your network. To observe the effectiveness of your model, you will be testing your model on :\n",
        "\n",
        "1. Unseen 3T MRI images,\n",
        "2. Noisy 3T MRI images and\n",
        "3. Use a qualitative metric: Peak signal to noise ratio (PSNR) to evaluate the performance of the reconstructed images.\n",
        "\n",
        "\n",
        "This tutorial will not be addressing the intricacies of medical imaging but will be focused on the deep learning side! Note : This tutorial will mostly cover the practical implementation of convolutional autoencoders. So, if you are not yet aware about **convolutional neural network (CNN) and autoencoder**, you might want to look at CNN and Autoencoder tutorial. The best part about this tutorial is that you will be loading the 3D volumes as 2D images and will be feeding them in to the model. In a nutshull, you will address the following topics in today's tutorial:\n",
        "\n",
        "In the beginning you will be briefed about Magnetic Resonance Imaging (MRI),\n",
        "Then you will understand about the Brain MRI dataset: what kind of images it has, importing the modules, how to read the images, creating an array of the images, preprocessing the brain MRI images to be able to feed them in the model and finally explore the brain MRI images.\n",
        "\n",
        "In the implementation of convolutional autoencoder: you will Fit the preprocessed data into the model, visualize the training and validation loss plot, sabe the trained model and finally predict on the test set.\n",
        "\n",
        "Next, you'll will test the Robustness of your pre-trained model by adding noise into the test images and see how well the model performs quantitatively.\n",
        "\n",
        "Finally, you will test your predictions using a quantitative metric peak signal-to-noise ratio (PSNR) and measure the performance of your model.\n",
        "\n",
        "**Brief Introduction on MR images**\n",
        "\n",
        "\n",
        "A variety of systems are used in medical imaging ranging from open MRI units with magnetic field strength of 0.3 Tesla (T) to extremity MRI systems with field strengths up to 1.0 T and whole-body scanners with field strengths up to 3.0 T (in clinical use). Tesla is the unit of measuring the quantitative strength of magnetic field of MR images. High field MR scanners (7T, 11.5T) yielding higher SNR (signal-to-noise ratio) even with smaller voxel (a 3-dimensional patch or a grid) size and are thus preferred for more accurate diagnosis.\n",
        "\n",
        "A smaller voxel size leads to a better resolution, which can in turn aid clinical diagnosis. However, the strength of magnetic field being used in MR scanner puts a lower bound on voxel size to maintain a good signal to noise ratio (SNR), in order to preserve the MR image details.\n",
        "Despite the superior image quality of 7T and 11.5T, they are rarely deployed in production due to its cost constraints.\n",
        "\n",
        "According to the recent papers, the reported number of 3T scanners are ~20,000 compared to just ~40 7T scanners.\n",
        "\n",
        "**Understanding the Brain MRI 3T Dataset**\n",
        "\n",
        "The brain MRI dataset consists of 3D volumes each volume has in total 207 slices/images of brain MRI's taken at different slices of the brain. Each slice is of dimension 173 x 173. The images are single channel grayscale images. There are in total 30 subjects, each subject containing the MRI scan of a patient. The image format is not jpeg,png etc. but rather nifti format. You will see in later section how to read the nifti format images.\n",
        "\n",
        "The dataset consists of T1 modality MR images, T1 sequences are traditionally considered good for evaluation of anatomic structures. The dataset on which you will be working today consists of 3T Brain MRI's.\n",
        "\n",
        "The dataset is public and is available for download at this source.\n",
        "\n",
        "Tip: if you want to learn how to implement an Multi-Layer Perceptron (MLP) for classification tasks with the MNIST dataset, check out this tutorial.\n",
        "\n",
        "Note : Before you begin please note that the model will be trained on a system with Nvidia 1080 Ti GPU Xeon e5 GeForce processor with 32GB RAM. If you are using Jupyter Notebook, you will need to add three more lines of code where you specify CUDA device order and CUDA visible devices using a module called os.\n",
        "\n",
        "In the code below, you basically set environment variables in the notebook using os.environ. It's good to do the following before initializing Keras to limit Keras backend TensorFlow to use first GPU. If the machine on which you train on has a GPU on 0, make sure to use 0 instead of 1. You can check that by running a simple command on your terminal: for example, nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWN44FhPhI74"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5CxqFnrhOZK"
      },
      "source": [
        "**Importing the modules**\n",
        "\n",
        "First, you import all the required modules like cv2, numpy, matplotlib and most importantly keras, since you'll be using that framework in today's tutorial!\n",
        "In order to read the nifti format images, you also have to import a module called nibabel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJov9hMPhTKA"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgBiEajmhav_"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.misc\n",
        "import numpy.random as rng\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from sklearn.utils import shuffle\n",
        "import nibabel as nib #reading MR images\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkp1SPEyiAj8"
      },
      "source": [
        "**Loading the data**\n",
        "\n",
        "You will use glob module which will return a list comprising of all the volumes in the folder that you specify!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3cGGJziJc_"
      },
      "source": [
        "ff = glob.glob('/content/drive/My Drive/Colab Notebooks/TFM/Datos/IXI-T1/*')\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL3nZeS6iRTb"
      },
      "source": [
        "Let's print the first element of the list and also check the length of the list: which in our case should be 30."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgFlByKdiTW2",
        "outputId": "3c1848a8-93e1-4a3a-a23d-cc68b97faf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ff[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/TFM/Datos/IXI-T1/IXI023-Guys-0699-T1.nii.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7og6bLuZxZ28"
      },
      "source": [
        "Let's print the first element of the list and also check the length of the list: which in our case should be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjLBlwNexdB2",
        "outputId": "9f731469-464d-4a13-8ed9-7e2eb5f5da76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ff)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGStA_trxh3t"
      },
      "source": [
        "Now you are all set to load the 3D volumes using nibabel. Note that when you load a Nifti format volume, Nibabel does not load the image array. It waits until you ask for the array data. The normal way to ask for the array data is to call the get_data() method.\n",
        "\n",
        "Since you want the 2D slices instead of 3D, you will initialise a list in which; every time you read a volume, you will iterate over all the complete 207 slices of the 3D volume and append each slice one by one in to a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj0INwe-xk6d"
      },
      "source": [
        "images = []"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZP_y-ifxrLd"
      },
      "source": [
        "Let's also print the shape of one of the 3D volume, it should be of the shape 256 x 256 x 130 (x, y, z; coordinates) ó 256 x 256 x 150\n",
        "\n",
        "Note : You will be using only the middle 51 slices of the brain and not all the 207 slices. So, let's also see how to use only the center slices and load them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6DE4UxDxtZ1",
        "outputId": "de69d55f-4b7d-4d83-a4db-6bdd4d3cc3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "for f in range(0, 30):\n",
        "    print(f)\n",
        "    b = nib.load(ff[f])\n",
        "    #header = a.header\n",
        "    #images.append (header.get_data_shape())\n",
        "    #print(header.get_data_shape()\n",
        "    b = b.get_fdata()\n",
        "    #print(b.shape)\n",
        "    if b.shape[2] == 130:\n",
        "      #a = b.get_fdata()\n",
        "      a = b[:,78:80,:]\n",
        "      #print(type(a))\n",
        "      print(a.shape)\n",
        "      for i in range(a.shape[1]):\n",
        "          #print(i)\n",
        "          images.append((a[:,i,:]))\n",
        "#print (a.shape)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(256, 2, 130)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "(256, 2, 130)\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pFTsP7IyFio"
      },
      "source": [
        "Let's analyse shape of one slice out of 207 slices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cjmCHXgi5aR",
        "outputId": "8884c3dd-f171-443c-bb91-000c9978d4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWTHyI5SjZE1",
        "outputId": "826d0b08-45b9-4bde-c72d-c9de319a1c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "images = np.array(images)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-2bbd740f17cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (256,130) into shape (256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkHONRwMnVV0",
        "outputId": "f8da241f-2b1a-4967-a01c-d60c39d126d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-972d9bbd0d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}